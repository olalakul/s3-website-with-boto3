{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Website on S3 with boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T14:27:10.984178Z",
     "start_time": "2020-02-23T14:27:10.871994Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a Data Scientist, I do care that my projects are deployed and running in production, therefore my interest in Data Engineering and DevOps part. I also care, that business-users have access to insights and advanced visualizations that I produce. \n",
    "\n",
    "Therefore I make interactive visualizations with Jupyter notebooks. Each Jupyter notebook can easily be converted to HTML file (or HTML file and images), which in turn can constitute static website. I host those websites. \n",
    "\n",
    "AWS S3 is a perfect opportunity to host everything simple and quickly. Boto3 is AWS SDK for python. I am just starting with boto3 and I love it. No mouse-clicking, just python script. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will host a static Website on AWS S3 bucket using python script with boto3 library. No manual interaction with AWS console is needed. The content of the Website includes several/many files, all of which are locally saved in one _nested_ directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get access to AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all I need to get access to my AWS account.\n",
    "\n",
    "A lot of tutorials explain at this place, how to use your 'Access key ID' and your 'Secret access key' without exposing them in the code. \n",
    "\n",
    "But we  are on Bertelsmann Challenge Cloud, aren't we? We have learned the better way - creating Programmatic User at AWS. Actually we already created such a user during the course. Let us use it!\n",
    "\n",
    "With Programmatic User, the credentials are saved on your computer in ~/.aws/credentials file.\n",
    "Just choose the one of the profiles in this file. Then use the name of this profile (here 'default') to creating a boto3 session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T14:27:13.406155Z",
     "start_time": "2020-02-23T14:27:13.391175Z"
    }
   },
   "outputs": [],
   "source": [
    "session = boto3.Session(profile_name='default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also do not need to manually enter your region, it is available from session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T14:27:14.146505Z",
     "start_time": "2020-02-23T14:27:14.143095Z"
    }
   },
   "outputs": [],
   "source": [
    "current_region = session.region_name\n",
    "print(current_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client and Resource\n",
    "\n",
    "Boto3 has _client_ - and _resource_ -level access to AWS. Resource represent an object-oriented  interface to AWS, this is a higher-level abstraction than a client. See [a short explanation here](https://stackoverflow.com/questions/42809096/difference-in-boto3-between-resource-client-and-session).\n",
    "\n",
    "My purpose is to use _resource_ level only. I use the [documentation here](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#service-resource)\n",
    "\n",
    "For people interested in _client_ level, I recommend the [GitHub of Balazs Kocsis](https://github.com/bkocis/bertelsmann-dsml-group-projects/blob/master/Project-boto/AWS-SDK-for-python-boto3.ipynb)\n",
    "\n",
    "First I create _resource_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T14:27:14.994137Z",
     "start_time": "2020-02-23T14:27:14.919022Z"
    }
   },
   "outputs": [],
   "source": [
    "s3_resource = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIME types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T12:15:14.491424Z",
     "start_time": "2020-02-06T12:15:14.487403Z"
    }
   },
   "source": [
    "Before actually starting with bucket and file uploading, let me introduce the `mimetypes` python module. \n",
    "Just have a look at the dictionary, mapping filename extensions to MIME types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T14:27:16.451541Z",
     "start_time": "2020-02-23T14:27:16.447716Z"
    }
   },
   "outputs": [],
   "source": [
    "import mimetypes\n",
    "for fileext in ['.html', '.png']:\n",
    "    print('For file extension {:s} --> the MIME type is {:s}'.format(fileext, mimetypes.types_map[fileext]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to deal with unknown types, I convert it to _defaultdict_ with the default MIME type being 'application/octet-stream' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T14:27:18.043762Z",
     "start_time": "2020-02-23T14:27:18.039145Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "content_type = defaultdict(lambda: 'application/octet-stream', mimetypes.types_map)\n",
    "for fileext in ['.html', '.png', '.coffee']:\n",
    "    print('For file extension {:s} --> the MIME type is {:s}'.format(fileext, content_type[fileext]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why care about MIME type? Well, you need this to display your HTML file (in your Website) in browser.  When I uploaded files without specifying the MIME type explicitly, my files were not displayed. Instead I got an option to download the file.\n",
    "\n",
    "The content of my website is stored in the nested directory. So, I want to upload all the files from this directory. In AWS CLI I found the `--recursive` flag for this purpose. But how to do this with boto3?\n",
    "I only found the option to iterate over all the files. \n",
    "\n",
    "Now I am ready to create the bucket and upload the content of `target_dir`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bucket and upload files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T14:27:21.537393Z",
     "start_time": "2020-02-23T14:27:21.534694Z"
    }
   },
   "outputs": [],
   "source": [
    "target_dir = 'wholesale-more-frozen-products'\n",
    "bucket_name = target_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T14:27:22.345102Z",
     "start_time": "2020-02-23T14:27:22.342740Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----- test structure of nested directory\n",
    "# target_dir = bucket_name\n",
    "# for subdir, dirs, files in os.walk(target_dir):\n",
    "#     print(subdir)\n",
    "#     #print(dirs)\n",
    "#     for file in files:\n",
    "#         print(\"\\t\", os.path.join(subdir, file)) #.replace(target_dir+'/', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T14:27:23.074348Z",
     "start_time": "2020-02-23T14:27:23.070765Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_bucket(s3_resource, aws_region, bucket_name):\n",
    "    try:\n",
    "        s3_resource.create_bucket(Bucket=bucket_name,\n",
    "                         CreateBucketConfiguration={'LocationConstraint': aws_region})\n",
    "    except ClientError as err:\n",
    "        print(err)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T14:27:23.884451Z",
     "start_time": "2020-02-23T14:27:23.878669Z"
    }
   },
   "outputs": [],
   "source": [
    "def upload_nested_directory(s3_resource, aws_region, bucket_name, target_dir):\n",
    "    if not os.path.isdir(target_dir):\n",
    "        raise ValueError('target_dir %r not found.' % target_dir)\n",
    "        \n",
    "    for subdir, dirs, files in os.walk(target_dir):\n",
    "        for file in files:\n",
    "            filename = os.path.join(subdir, file)\n",
    "            s3_path = filename.replace(target_dir+'/', '')\n",
    "            fileext = '.'+file.split('.')[-1]  # file extension\n",
    "            s3_resource.Object(bucket_name, s3_path).put(Body=open(filename, 'rb'),\n",
    "                                                          ACL = 'public-read',\n",
    "                                                          ContentType = content_type[fileext])\n",
    "    \n",
    "            print('File uploaded to https://s3.%s.amazonaws.com/%s/%s' % (\n",
    "                                                    aws_region, bucket_name, s3_path))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T14:27:32.109221Z",
     "start_time": "2020-02-23T14:27:25.230829Z"
    }
   },
   "outputs": [],
   "source": [
    "create_bucket(s3_resource=s3_resource, aws_region=current_region, bucket_name=bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T14:49:16.701095Z",
     "start_time": "2020-02-06T14:49:04.949306Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "upload_nested_directory(s3_resource=s3_resource, aws_region=current_region, \n",
    "                        bucket_name=bucket_name, target_dir=target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us list all files in the bucket to ensure that everyting is uploaded properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucket subresource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a bucket sub-resource, from which I can access all objects and their properties in object-oriented manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:03:27.248053Z",
     "start_time": "2020-02-07T08:03:26.293811Z"
    }
   },
   "outputs": [],
   "source": [
    "bucket = s3_resource.Bucket(bucket_name)\n",
    "for obj in bucket.objects.all():\n",
    "    print(obj.key, obj.last_modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can access my files in the bucket and directly (without downloading) see their content. My index document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:03:35.063534Z",
     "start_time": "2020-02-07T08:03:35.061122Z"
    }
   },
   "outputs": [],
   "source": [
    "index_document = 'wholesale-moreFrozenProducts.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T12:01:54.185173Z",
     "start_time": "2020-02-23T12:01:54.181737Z"
    }
   },
   "source": [
    "can be accessed via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:03:35.991994Z",
     "start_time": "2020-02-07T08:03:35.988816Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"http://{}.s3.amazonaws.com/{}\".format(bucket_name, index_document))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to use the link above. It works for me. Does it for you?\n",
    "\n",
    "Are we done? Is this my website? The point of calling it 'website' is having the endoint without specifying the index page explicitly. To rephase it, the website should know its index page itself. So I need to set the website configuration first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error and Index documents for website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am creating the BucketWebsite sub-resource and specifying the _index_ and _error_ documents of my website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:43:17.786136Z",
     "start_time": "2020-02-07T08:43:17.782899Z"
    }
   },
   "outputs": [],
   "source": [
    "bucket_website = s3_resource.BucketWebsite(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:43:18.232879Z",
     "start_time": "2020-02-07T08:43:18.230179Z"
    }
   },
   "outputs": [],
   "source": [
    "website_configuration = {\n",
    "    'ErrorDocument': {'Key': 'error.html'},\n",
    "    'IndexDocument': {'Suffix': index_document},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:43:19.533298Z",
     "start_time": "2020-02-07T08:43:18.679823Z"
    }
   },
   "outputs": [],
   "source": [
    "bucket_website.put(WebsiteConfiguration=website_configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the website configuration use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:43:21.190679Z",
     "start_time": "2020-02-07T08:43:20.999567Z"
    }
   },
   "outputs": [],
   "source": [
    "print(bucket_website.error_document)\n",
    "print(bucket_website.index_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, I did not found a way to get the endpoint of the website programatically from the `bucket-website` sub-resource. It there a way? So, let us construct it manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:04:39.367183Z",
     "start_time": "2020-02-07T08:04:39.363578Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"http://{}.s3-website.{}.amazonaws.com/\".format(bucket_name, current_region))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I get access to the website without specifying the index document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete website configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T12:42:13.081867Z",
     "start_time": "2020-02-06T12:42:13.077668Z"
    }
   },
   "source": [
    "To save AWS resources, I can delete the website (but won't do it here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:42:41.414803Z",
     "start_time": "2020-02-07T08:42:40.650178Z"
    }
   },
   "outputs": [],
   "source": [
    "bucket_website.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since my files are still in the bucket, I can access them directly by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T12:43:15.526563Z",
     "start_time": "2020-02-06T12:43:15.523036Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"http://{}.s3.amazonaws.com/{}\".format(bucket_name, index_document))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete files in the bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can delete all files in the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T14:45:26.633129Z",
     "start_time": "2020-02-06T14:45:21.212564Z"
    }
   },
   "outputs": [],
   "source": [
    "for obj in bucket.objects.all():\n",
    "    obj.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As soon as the bucket is empty, I can delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T14:10:22.008859Z",
     "start_time": "2020-02-06T14:10:21.607366Z"
    }
   },
   "outputs": [],
   "source": [
    "response = bucket.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-23T12:13:03.253038Z",
     "start_time": "2020-02-23T12:13:03.247622Z"
    }
   },
   "source": [
    "By the way, in AWS CLI I found a way to delete a _nonempty_ bucket with `--force` flag like\n",
    "\n",
    "    aws s3 rb s3://my-example-bucket –-force\n",
    "    \n",
    "In boto3 I found nothing similar. Do you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
